Title: Why Agent Frameworks Will Fail (and what to use instead)
Channel: Dave Ebbelaar
Published: 2024-06-27T15:26:54Z
Duration: PT19M21S
Description: Want to get started with freelancing? Let me help: https://www.datalumina.com/data-freelancer
Need help with a project? Work with me: https://www.datalumina.com/solutions

You probably don't need an agent framework to solve your automation problem. In this video, I'll cover my approach.

üëãüèª About Me
Hi there! I'm Dave, an AI Engineer and the founder of Datalumina. On this channel, I share practical coding tutorials to help you become better at building intelligent systems. If you're interested in that, consider subscribing!

Transcript:

[00:00:00] in this video I'm going to give you my
[00:00:01] take on agent Frameworks I'm going to
[00:00:03] tell you why I think they will fail and
[00:00:05] what to use instead if you don't know
[00:00:07] who I am my name is Dave abar I'm the
[00:00:09] founder of data Lumina and I've been
[00:00:11] building custom data and AI solutions
[00:00:13] for the past 5 years and next to that I
[00:00:15] create educational content like this to
[00:00:17] help you do the same and ultimately
[00:00:19] start freelancing so let's dive into
[00:00:21] this video so with the rise of large
[00:00:23] language models so-called agentic
[00:00:25] workflows and Frameworks became really
[00:00:28] popular and as a result we saw a lot of
[00:00:29] them pop up so for example we have
[00:00:31] autogen we have crew Ai and also Lang
[00:00:33] chain has a way to build agents and you
[00:00:36] have a lot more and the problem with all
[00:00:40] of these all of those Frameworks is that
[00:00:43] most of them are probably way too
[00:00:46] complex for what you're trying to do and
[00:00:48] not robust enough for what you're trying
[00:00:50] to do so let me
[00:00:52] explain all of these tools in all of
[00:00:54] these Frameworks are really most of them
[00:00:56] are built around the core idea of
[00:00:59] chaining agents together in a way where
[00:01:02] they can reason and figure out the next
[00:01:04] step within some kind of workflow so
[00:01:07] here if you look at the definition by
[00:01:09] Lang chain the core idea of an agent is
[00:01:10] to use a language model so an LM to
[00:01:12] choose a sequence uh of actions to take
[00:01:15] in a chain so a language model is used
[00:01:18] as a reasoning engine to determine which
[00:01:20] action to take crew AI follows a similar
[00:01:24] approach where you can very easily
[00:01:26] design agents you can give them tasks
[00:01:29] and I believe there's also this allowed
[00:01:31] delegation parameter that you can fill
[00:01:33] in so agents have Back stories roles
[00:01:36] goals and depending on the overall
[00:01:38] system they can decide the next PATH to
[00:01:41] take and the result of that is really
[00:01:45] cool and creative in a way that every
[00:01:48] time you run this you can get different
[00:01:50] outcomes you can get new stories you can
[00:01:53] build really cool processes for this but
[00:01:57] the problem what I found is that most
[00:01:59] most of the processes in the real world
[00:02:02] right now that you want to automate for
[00:02:04] a business for example does not require
[00:02:07] that much room for
[00:02:09] creativity actually mostly it's the
[00:02:12] other way around you want to take a
[00:02:14] process that is very clearly defined and
[00:02:17] if it's not defined you want to you want
[00:02:18] to Define that and then figure out the
[00:02:22] sequence of steps the sequence of
[00:02:23] actions to automate that workflow and
[00:02:27] then whenever you need AI to solve a
[00:02:30] particular step within that chain of
[00:02:33] problems that is where a large language
[00:02:35] model comes in so let's take a look at
[00:02:38] this example so I've been building apps
[00:02:41] using large language models literally
[00:02:42] since the day GPT 3.5 came out and in
[00:02:47] general if you look at the app flow of
[00:02:49] all of these applications it follows
[00:02:51] this process you have inputs in the form
[00:02:53] of your data your prompts then there is
[00:02:55] a processing layer which can be one
[00:02:58] simple processing step one llm call or
[00:03:00] it could be a chain of events multiple
[00:03:03] llm calls intermediate function
[00:03:05] processing steps external API calls
[00:03:08] whatever there could be a lot of
[00:03:09] processing and finally there's always
[00:03:11] some sort of output because when you're
[00:03:13] using generative AI these models create
[00:03:15] something they create output and
[00:03:17] typically you want to store that either
[00:03:19] in a database make it available to a
[00:03:21] front end in a chat application or
[00:03:23] whatever input processing
[00:03:26] output that is how these projects are
[00:03:29] setup now if you look at the agentic
[00:03:33] framework flow of how agentic Frameworks
[00:03:36] are trying to solve this problem it
[00:03:39] looks something like this and this is a
[00:03:41] very simplified version but really
[00:03:43] what's going on they take that input and
[00:03:46] then that processing layer that is where
[00:03:48] all of the agent comes in and typically
[00:03:50] there is some kind of a manager or
[00:03:52] orchestrator in between that can
[00:03:54] interact with all of these agents who
[00:03:56] all have specific goals Back stories and
[00:03:59] tasks so let's come back to crew over
[00:04:02] here here you can see initiate the crew
[00:04:04] so you have the crew the agents and the
[00:04:06] tasks so that is what I would refer to
[00:04:08] as the manager that is where you would
[00:04:11] bring everything together but when we
[00:04:14] look at all of these agents and the
[00:04:15] manager as a whole all of this is
[00:04:18] typically connected well it doesn't have
[00:04:20] to be the case you could also make it
[00:04:22] sequential but in general this is the
[00:04:25] agent work framework philosophy where
[00:04:28] there you have a lot of a agents working
[00:04:30] together so agent one might do something
[00:04:32] pass it onto agent two but then agent
[00:04:34] three might need something from agent
[00:04:36] one Etc and if agent 3 thinks the output
[00:04:39] is not good enough we go back to agent
[00:04:41] one and eventually if everyone agrees we
[00:04:44] pass it on to the manager and then we
[00:04:45] have the output so that would that would
[00:04:49] result in the flow that you you see over
[00:04:52] here and autogen and building agents
[00:04:54] with Lang chain all follow similar
[00:04:57] processes and the problem with that how
[00:04:59] I see it is we are literally
[00:05:01] collectively all trying to figure out
[00:05:03] the best way to build applications
[00:05:06] around language models large language
[00:05:08] models we're trying to figure out the
[00:05:10] best workflows we're trying to figure
[00:05:11] out how to do this at scale how to
[00:05:13] manage hallucinations and all of these
[00:05:15] tools they have their own opinionated
[00:05:18] way of going about it and don't get me
[00:05:21] wrong I don't want to bash these tools
[00:05:22] they're great for certain use cases I
[00:05:24] just want to point out that I believe
[00:05:26] for most of the automation use cases for
[00:05:28] businesses right now I wouldn't
[00:05:31] recommend using these tools because like
[00:05:34] I've said you're building on top of
[00:05:36] abstractions that other developers came
[00:05:40] up with in a new field which we are all
[00:05:43] still trying to figure out and because
[00:05:45] you're building on top of these
[00:05:46] extractions like this you probably don't
[00:05:50] know what's going on behind the scenes
[00:05:51] because that's really hard to understand
[00:05:53] if you dive into a new bloated library
[00:05:56] that you didn't write yourself so what I
[00:05:59] recommend instead is keeping things
[00:06:01] really simple and building these
[00:06:03] applications up really from the ground
[00:06:05] really from first principes so really
[00:06:08] consider for your situation for your
[00:06:10] application what it is that what is it
[00:06:13] that you need and what are the steps
[00:06:15] required in order to solve this problem
[00:06:18] and if we go back to the Whiteboard the
[00:06:20] way I currently do that which I will
[00:06:21] show you an example in a bit is I view
[00:06:24] the generative AI app flow not as an
[00:06:28] agentic problem to solve but rather I
[00:06:31] look at it as a data
[00:06:34] pipeline because if you look at the
[00:06:37] general FL flow input processing
[00:06:40] output it's very similar to a regular
[00:06:43] ETL pipeline extract transform load and
[00:06:46] the cool thing about data pipelines is
[00:06:48] they have literally been around for
[00:06:50] years ever since we had computers people
[00:06:53] have built data pipelines and there are
[00:06:56] a lot more solid principles designed
[00:06:59] patterns and approaches that we can
[00:07:02] leverage when we follow a data pipeline
[00:07:05] flow rather than an agentic workflow and
[00:07:09] also rather than designing your workflow
[00:07:12] using circular patterns where for
[00:07:14] example agent 3 can jump back to agent
[00:07:17] one to two and then back to one you
[00:07:20] ideally at least how I like to do it is
[00:07:22] I design my pipelines using a sequential
[00:07:26] approach so following a what's known as
[00:07:29] as a directed acyclic graph or DAC which
[00:07:32] is also what tools like airf flow are uh
[00:07:35] built on top of on that design principle
[00:07:38] meaning that data can only flow one way
[00:07:42] and not go back and this overall ensures
[00:07:46] the reliability of your system because
[00:07:49] in my opinion you should really design
[00:07:51] your workflows in a way that if the
[00:07:54] pipeline if the flow ends up at three it
[00:07:57] should already have processed one and
[00:07:59] two the outputs so that you can always
[00:08:02] continue with three and it's just about
[00:08:05] how you how you frame the problem and
[00:08:08] that's why the sequential order really
[00:08:10] helps for that so you always know it's
[00:08:13] first this step then this step and in
[00:08:15] between you can add all kinds of logic
[00:08:17] and validation but if your business
[00:08:19] process or automation process if you
[00:08:21] can't draw it out like this using simple
[00:08:24] sequential steps I recommend you to go
[00:08:27] back to the Whiteboard and try to make
[00:08:29] it simpler or split it up even further
[00:08:31] because almost every process for for
[00:08:34] most business problems that you're
[00:08:35] trying to solve they can be broken down
[00:08:38] like this and now the cool thing about
[00:08:40] viewing the problem that you're trying
[00:08:41] to solve with an llm as a data pipeline
[00:08:46] rather than an agentic framework or
[00:08:48] workflow is that it becomes much simpler
[00:08:51] to solve this using code without needing
[00:08:55] any fancy Frameworks or tools so let me
[00:08:59] quickly show you an example so I'm going
[00:09:01] to show you an example in Python but
[00:09:03] again the cool thing is you can do this
[00:09:05] in any language because it doesn't
[00:09:08] matter if you follow the similar steps
[00:09:11] of getting your data chaining together
[00:09:14] steps in a data pipeline bringing it all
[00:09:16] together and then pushing it to whatever
[00:09:18] kind of output you're pushing it to it
[00:09:20] doesn't matter what language you use and
[00:09:22] you don't need any framework so let me
[00:09:24] show you an example this is a project
[00:09:27] template that I'm building out so it's
[00:09:29] called generative AI project template
[00:09:31] it's pretty complex there are a lot of
[00:09:32] moving parts and we're building this
[00:09:34] internally for our company but I'm going
[00:09:36] to show you the pipeline process in
[00:09:39] there because that's what what we're
[00:09:40] talking about right now so we're
[00:09:42] currently using the example of creating
[00:09:45] a system that can take an incoming email
[00:09:49] then classify it and then generate a
[00:09:52] reply so this could be what you call an
[00:09:55] agent workflow or a problem that you can
[00:09:57] solve using a large language model now
[00:10:00] the cool thing about designing these
[00:10:03] pipelines and these solutions for these
[00:10:04] problems is that you can have one step
[00:10:07] or you could have 100 steps it doesn't
[00:10:10] matter and ideally in your code you want
[00:10:13] to build it in such a way that you can
[00:10:16] easily add steps and remove steps and
[00:10:19] change steps now a very common design
[00:10:22] pattern to do this is the chain of
[00:10:25] responsibility pattern so I've used that
[00:10:28] particular patter pattern I will show
[00:10:30] you in a bit what that looks like and
[00:10:32] give it my own spin to it by including
[00:10:34] some pipeline elements into it and now
[00:10:38] being able to very easily Define
[00:10:41] sequential steps and then in between
[00:10:44] when it's time to call the large
[00:10:45] language model we do that so let's see
[00:10:47] what's going on over here we're
[00:10:49] simulating an incoming ticket here from
[00:10:52] a ticketing system so let me zoom in a
[00:10:54] little bit so let's assume we we're
[00:10:56] getting in some data and the ticketing
[00:10:58] system ident I okay this is from an
[00:11:00] email this is from uh info datal um.com
[00:11:03] and it's an email asking for a potential
[00:11:06] collaboration now the cender here is dat
[00:11:09] luminat reaching out to me so that would
[00:11:10] be a little bit weird but you get the
[00:11:12] idea we're getting some input data here
[00:11:14] and throughout this project um we have
[00:11:17] identified some pipelines and for this
[00:11:20] ticketing system we are going to Define
[00:11:23] in at first two pipelines just for
[00:11:26] example so we have tickets coming in
[00:11:27] from email and we have tickets coming in
[00:11:30] from Instagram so what you how you can
[00:11:32] then view that is you have your data
[00:11:34] Pipeline and you have another one for
[00:11:37] Instagram so this could be ebil this
[00:11:39] could be Instagram and again you could
[00:11:41] infinitely duplicate this to expand your
[00:11:45] system so the whole idea with this
[00:11:47] project really is that everything has a
[00:11:49] nice and tidy place for it so we have
[00:11:52] our pipelines so let's see at what that
[00:11:56] then looks like if we come in here and
[00:11:58] we process the task so we take that data
[00:12:01] we're using ptic models and we call
[00:12:03] process the tasks we then call a
[00:12:06] pipeline registry which is using a
[00:12:10] registry design pattern again a design
[00:12:12] pattern that is solid that is proven and
[00:12:15] what this does is depending on whether
[00:12:18] the channel is email or Instagram we get
[00:12:21] the right pipeline so again through that
[00:12:23] frame we have different pipelines data
[00:12:25] comes in system figures out okay we need
[00:12:28] this pipeline so we can route uh
[00:12:31] different requests to the right place
[00:12:34] okay let's go one step further and look
[00:12:37] at what a pipeline actually is so let's
[00:12:39] consider the email pipeline the email
[00:12:42] pipeline is a sequence of steps first we
[00:12:45] have classify email and then we have
[00:12:47] generate response so in this case we're
[00:12:49] only using two steps but like I've said
[00:12:52] you can make this infinitely complex by
[00:12:56] simply adding more steps to the system
[00:12:59] and this is where the chain of
[00:13:02] responsibility pattern comes in so let
[00:13:05] me come back to the registry let's look
[00:13:07] at the email Pipeline and look at the
[00:13:08] base pipeline so the base pipeline step
[00:13:12] is configured with a run function where
[00:13:15] it Loops over all of the steps in the
[00:13:18] pipeline and then calls the step.
[00:13:20] process which processes all of the data
[00:13:23] and you can see there is an abstract
[00:13:25] method in here called process and it's
[00:13:27] just used to pass around the data
[00:13:29] between the different steps now I'm
[00:13:32] covering this high level if you want to
[00:13:34] know more about this let me know in the
[00:13:36] comments um you could research these
[00:13:38] design patterns on your own really the
[00:13:40] idea is not here to really get in great
[00:13:43] detail on how this works but rather show
[00:13:45] you how simple it can be by combining
[00:13:49] two design patterns and putting that
[00:13:51] together in a structured way so
[00:13:54] following all of that let's look at the
[00:13:56] two processing steps that we in have in
[00:13:59] here so we have a classify email which
[00:14:01] leverages the instructor Library if you
[00:14:04] don't know what the instructor library
[00:14:05] is you can use it to patch large
[00:14:07] language models and use it to uh
[00:14:11] validate your your output by defining a
[00:14:14] response model this is really powerful
[00:14:17] and will completely change the way you
[00:14:19] build applications around large language
[00:14:21] models I have a video on that as well
[00:14:23] which I will link afterwards but this is
[00:14:25] really big now what this all allows you
[00:14:28] to do let me zoom out a little bit is
[00:14:31] having one simple input over here and if
[00:14:34] I run this we can have a look uh we have
[00:14:37] the function over here and now we can
[00:14:38] just process this so let's just process
[00:14:40] this and see what happens and now it
[00:14:42] will just trigger the pipeline so it
[00:14:43] will run it will step one step two it
[00:14:46] will pass down the data and it
[00:14:49] will fire or it will run the processing
[00:14:52] steps as defined in the classes over
[00:14:56] here but now let's look at the cool
[00:14:58] thing
[00:14:59] let's let's see where is it let's look
[00:15:01] at the cool thing is so first we have
[00:15:04] the classification so it says it's
[00:15:06] collaboration it also adds a confidence
[00:15:08] score because I've asked it to we can
[00:15:10] validate it with penic and we also ask
[00:15:13] reasoning which is something I really
[00:15:14] like to do so next to just defining an
[00:15:17] output you also ask the the model to
[00:15:19] give a reasoning and that is then used
[00:15:24] in your system via logging or in a
[00:15:25] database to backtrack something to debug
[00:15:28] to reduce hallucinations and then over
[00:15:31] here we have the response and it says
[00:15:34] thank you for reaching out we appreciate
[00:15:36] your interest however we're currently
[00:15:37] not pursuing any collaborations and that
[00:15:39] is because there's a prompt folder over
[00:15:41] here um where we've created The Prompt
[00:15:44] and we can introduce some guidelines
[00:15:47] here for the system to consider okay so
[00:15:50] that's the output but now let's look at
[00:15:53] what is happening behind the scenes and
[00:15:55] what we get back so the result is now a
[00:15:57] task result
[00:15:59] and instead of a single like text output
[00:16:03] we have a dictionary with if this runs
[00:16:06] in production we have a task ID from
[00:16:08] saler we have the status it's completed
[00:16:10] we have the input data which is the
[00:16:12] original data we have processing context
[00:16:14] which is any context or any any
[00:16:17] intermediate steps that you need
[00:16:20] throughout the system so let me explain
[00:16:23] so for example in step one you might
[00:16:25] calculate or you might determine the
[00:16:26] category of the email then you might
[00:16:28] save that as an intermediate step and
[00:16:32] then use that in step two to for example
[00:16:35] get the right data through uh or the
[00:16:38] right contacts through a rack system
[00:16:41] that is an an an that is how you could
[00:16:43] use that for example so you store any
[00:16:45] intermediate data for example the
[00:16:47] category in there and then you also have
[00:16:50] the output data which in this case is
[00:16:52] the response and we're building this out
[00:16:56] so that we follow a a uh penic we follow
[00:17:01] ptic U models let me actually come in
[00:17:04] here and this is still work in progress
[00:17:06] where we have a predefined structure for
[00:17:08] input processing output task results and
[00:17:11] the events that come in so that we can
[00:17:13] use it for all of our generative AI
[00:17:15] problems and again if you want to know
[00:17:17] more about this uh I plan to do a whole
[00:17:20] video on this discovering this but we're
[00:17:22] still working this out and also that's
[00:17:24] not the goal because again I'm also
[00:17:27] right now in a sense creating my own
[00:17:29] extractions and my own systems and the
[00:17:33] goal really is to show you that you
[00:17:35] probably don't need someone else's
[00:17:37] framework figure out what your problem
[00:17:42] what your problem needs how to solve
[00:17:43] that problem using a simple data
[00:17:45] Pipeline and then build it up from the
[00:17:47] ground from first principle so that one
[00:17:50] you fully understand it and it doesn't
[00:17:52] become too blo it and now here to
[00:17:54] quickly demonstrate that if we come over
[00:17:56] here to Let's process the Instagram task
[00:17:58] so so you can see channel is now
[00:18:00] Instagram we have a username uh let's
[00:18:03] see so we got this and then we process
[00:18:05] that task and we can look at the results
[00:18:08] and that is currently uh coded to to
[00:18:10] generate the hardcoded reply but you can
[00:18:12] see that it correctly takes on the
[00:18:14] correct pipeline depending on the
[00:18:17] incoming user data and having built tons
[00:18:20] of generative AI applications this is
[00:18:24] typically what you want you filter the
[00:18:25] input you decide what comes in what kind
[00:18:27] of data what kind of user or what kind
[00:18:29] of platform you want to follow
[00:18:31] sequential processing steps and then
[00:18:33] output it to another system so that's it
[00:18:36] for this video and by the way if you're
[00:18:38] a developer and you want to get started
[00:18:39] with freelancing but struggle to find
[00:18:41] clients you might want to check out the
[00:18:43] first link in the description it's a
[00:18:45] video of me going over how my company
[00:18:48] can help you solve that problem and now
[00:18:50] in all transparency it's a funnel
[00:18:51] designed to get leads for my company so
[00:18:54] please keep that in mind you don't have
[00:18:55] to click it but if you want to get
[00:18:57] started with freelancing but don't know
[00:18:58] how to get get started go check it out
[00:19:00] and now if you found this video helpful
[00:19:02] please leave a like and also consider
[00:19:04] subscribing and then if you want to
[00:19:06] learn more about building reliable
[00:19:08] systems with large language models for
[00:19:10] example using the instructor Library
[00:19:12] make sure to check out this video next
[00:19:15] where I go over my entire workflow
[00:19:17] really deep diving into how you can set
[00:19:19] this up for yourself
