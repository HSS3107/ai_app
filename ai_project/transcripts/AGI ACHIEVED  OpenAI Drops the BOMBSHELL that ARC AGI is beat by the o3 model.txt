Title: AGI ACHIEVED | OpenAI Drops the BOMBSHELL that ARC AGI is beat by the o3 model
Channel: Wes Roth
Published: 2024-12-21T05:43:14Z
Duration: PT17M36S
Description: The latest AI News. Learn about LLMs, Gen AI and get ready for the rollout of AGI. Wes Roth covers the latest happenings in the world of OpenAI, Google, Anthropic, NVIDIA and Open Source AI.

My Links üîó
‚û°Ô∏è Subscribe: https://www.youtube.com/@WesRoth?sub_confirmation=1
‚û°Ô∏è Twitter: https://x.com/WesRothMoney
‚û°Ô∏è AI Newsletter: https://natural20.beehiiv.com/subscribe

#ai #openai #llm

Transcript:

[00:00:00] I took one day off because I needed to
[00:00:01] get my mom from the airport and that's
[00:00:04] the day open ey decides to drop AGI what
[00:00:07] is the chance of that this is Agi I
[00:00:10] think it's going to be hard to deny it
[00:00:12] moving forward December 20 2024 open a
[00:00:15] announced AGI on a live stream all the
[00:00:18] tests and benchmarks that are used up
[00:00:20] until this point to see how smart these
[00:00:22] models were compared the models ability
[00:00:25] to that of humans for example Arc AGI
[00:00:28] Human Performance was 85 they said if
[00:00:30] ever some model got above 85 that would
[00:00:33] indicate that we're dealing with AGI
[00:00:36] artificial general intelligence 03
[00:00:39] scores 88% on the competition coding
[00:00:42] questions code forces it gets
[00:00:44] 2727 yakob the chief science officer at
[00:00:48] openi scored less competition math aim
[00:00:52] 2024 scores
[00:00:54] 96.7 we had people that had perfect
[00:00:57] scores but again I mean it might miss
[00:00:59] one question or one detail but it's
[00:01:01] pretty much there PhD level science
[00:01:04] questions at the gpq a diamond the
[00:01:06] average PhD level person the expert in
[00:01:09] that field gets 70% 03 gets
[00:01:13] 87.7 most of these benchmarks where we
[00:01:15] compare these models to human
[00:01:18] performance they're pretty much
[00:01:19] saturated they're pretty much maxed out
[00:01:22] these models aren't smarter than the
[00:01:24] average human they're Now smarter than
[00:01:26] the smartest humans Greg comrad the
[00:01:29] president of the The Arc Foundation said
[00:01:31] something that I found kind of
[00:01:33] interesting he said we need to all
[00:01:35] update our intuitions about what AI is
[00:01:38] and what it can do and certainly that
[00:01:40] seems true we've broken through some
[00:01:42] barrier here some wall human benchmarks
[00:01:45] for testing these models they're pretty
[00:01:47] much obsolete before most of our
[00:01:49] benchmarks looked like this you can get
[00:01:50] a score between let's say zero and 100%
[00:01:53] right humans were somewhere right here
[00:01:54] this is like the average sort of human
[00:01:56] ability or the expert human ability
[00:01:59] right and these model slowly got better
[00:02:00] and better and better and better and now
[00:02:02] they're pretty much maxing these out
[00:02:04] what comes next well sort of the scale
[00:02:06] changes now humans are here right this
[00:02:10] is the average human you know capable of
[00:02:12] uh doing 5% on some task right and
[00:02:14] here's Einstein he pulls a respectable
[00:02:16] seven smart guy but the new' 04 model
[00:02:19] that they released or whatever they're
[00:02:20] going to call it yeah that clct in at 42
[00:02:22] in other words it sort of exceeded the
[00:02:24] peak of biological intelligence and is
[00:02:27] now continuing into intelligence that's
[00:02:30] possible with these digital artificial
[00:02:32] neural Nets just take a second to grock
[00:02:36] that so to speak that just happened
[00:02:39] we've crossed into that now this isn't
[00:02:42] clickbait you already clicked on the
[00:02:43] video we are here now now if you watch
[00:02:47] the opening announcement basically they
[00:02:48] were saying how for a lot of these
[00:02:50] benchmarks they used a very aggressive
[00:02:53] test time compute so remember it's that
[00:02:55] idea that we're giving the AI model more
[00:02:58] time to think about the answer we're
[00:03:00] using more compute resources at test
[00:03:03] time right for it to think about the
[00:03:05] question so as opposed to sort of
[00:03:07] pouring more resources into it during
[00:03:09] training we're now increasing how much
[00:03:11] resources we give it during when we
[00:03:13] expect the answer to take place allowing
[00:03:15] it more time to think more time to
[00:03:18] reason with these o models 01 01 preview
[00:03:21] 03 I assume is the same way it has its
[00:03:24] own sort of internal thoughts that we're
[00:03:26] able to see or at least the open AI
[00:03:28] researchers are able to see so we give
[00:03:30] it the question and it gets to thinking
[00:03:32] and as it's thinking as those tokens and
[00:03:34] thoughts and words are rolling out it
[00:03:36] costs certain amount of money so the
[00:03:38] official score that the 03 received on
[00:03:41] this test on the sort of the official
[00:03:43] Arc AGI test was 76% which placed it at
[00:03:47] number one out of all the AI models ever
[00:03:50] tested Now sort of the the human
[00:03:52] Benchmark that they've said is is 85% so
[00:03:55] this is what we think of this is what
[00:03:56] humans are capable of although I've seen
[00:03:58] some people saying that that that may be
[00:04:00] sort of at the upper range of that it's
[00:04:01] probably a little bit less than that but
[00:04:03] 85 was The Benchmark the limit that they
[00:04:05] set so if a model gets over 85% we can
[00:04:08] consider it AGI but one of the rules
[00:04:10] that our AGI has is that the submissions
[00:04:13] can use up to
[00:04:14] $10,000 in resources right in compute
[00:04:17] that is the limit of how much compute
[00:04:20] they're able to use so this result of
[00:04:22] 76% so that's again the number one place
[00:04:26] for all the models that ever tested on
[00:04:27] this 76% that's what it God following
[00:04:30] the rules of not using High compute not
[00:04:33] going over the $10,000 in resources
[00:04:36] however they ran it again with unlimited
[00:04:39] resources they said hey 03 model you
[00:04:42] just you just take whatever time you
[00:04:43] need to think about it like really think
[00:04:45] hard about this and it did now they
[00:04:48] didn't publish the number I think I read
[00:04:50] somewhere that rgi said that openi did
[00:04:53] not want that number published and so
[00:04:55] here are the open ai3 Arc egi results so
[00:04:58] they were testing against two of the
[00:05:00] data sets there were 100 private tasks
[00:05:02] to assess overfitting so overfitting is
[00:05:04] the opposite of generalization so we
[00:05:07] want these models to be able to
[00:05:08] generalize to unseen information it's
[00:05:11] like if you have a dog running five
[00:05:12] different obstacle courses we're hoping
[00:05:14] that that dog is going to be better at
[00:05:16] running all the other types of obstacle
[00:05:18] courses that it hasn't seen before it
[00:05:20] generalized its knowledge its skills to
[00:05:23] every other possible variation of that
[00:05:26] course to every other possible sort of
[00:05:29] way that can construct that course over
[00:05:31] fitting is the opposite it's when the
[00:05:32] model kind of just spits out its strum
[00:05:34] data but can't generalize to other
[00:05:37] questions that it hasn't seen before and
[00:05:39] so they have the sort of the retail cost
[00:05:41] how much it will cost for the compute
[00:05:43] and they're saying that the 03 High
[00:05:44] compute cost not available as pricing
[00:05:47] and feature availability still to be
[00:05:49] determined the amount of compute was
[00:05:50] roughly 172 times the low compute
[00:05:53] configuration so we don't know how much
[00:05:55] openi will be charging the retail cost
[00:05:57] of running this model but notice they're
[00:05:59] now talking that moving forward another
[00:06:02] required metric will be this sort of
[00:06:04] inference budget this efficiency they're
[00:06:06] saying that the sort of the total costs
[00:06:08] and the cost per task as a sort of proxy
[00:06:11] for efficiency we're going to need to
[00:06:12] figure out what metrics what metric is
[00:06:14] going to best track efficiency but you
[00:06:16] know cost is a good starting point and
[00:06:18] so the high efficiency score of 75.7 is
[00:06:22] within the budget rules of the arc AGI
[00:06:24] Pub so the costs are less than 10,000
[00:06:26] therefore qualifies as the first place
[00:06:28] on the public leader forward
[00:06:30] interestingly here so they've used for
[00:06:32] the high efficiency semi-private so so
[00:06:34] this is kind of the official results
[00:06:36] right so this is what they got the 75.7%
[00:06:38] on the the models used 33 million tokens
[00:06:42] and took a little bit over a minute per
[00:06:43] task but these semi-private right so
[00:06:46] that
[00:06:48] 87.5 that's the one where they said use
[00:06:50] more compute to figure this out they
[00:06:52] used 5.7 billion tokens and it ran 13.8
[00:06:56] minutes per task one thing that I found
[00:06:58] interesting here is they don't tell the
[00:07:00] retail cost of how much it cost to get
[00:07:03] this
[00:07:04] 87.5% they're not listing it there but
[00:07:07] they do tell you how many tokens it used
[00:07:09] up right so it used 5.7 billion tokens
[00:07:12] versus 33 million tokens for the high
[00:07:15] efficiency one does that mean we can
[00:07:17] figure out the you know retail cost of
[00:07:19] running this I actually had my ow and PR
[00:07:21] mode subscription so I just loaded a
[00:07:23] screenshot of that and asked it to
[00:07:25] figure out what is the cost for the low
[00:07:27] efficiency score and so it's estimated
[00:07:29] meaning that it would cost
[00:07:32] $347,000 run it for that long and let
[00:07:35] think that much in order to get that
[00:07:38] 87.5% score now if you're wondering why
[00:07:41] it chose to answer by saying waah wa
[00:07:43] wewa I do little Maps yes and then ended
[00:07:46] with great success on my last live
[00:07:48] stream somebody asked if I can make it
[00:07:50] speak like Borat and I've actually added
[00:07:53] that to the custom instructions and
[00:07:55] forgot to delete that but don't let that
[00:07:57] throw you off the math checks out either
[00:07:59] way I'm very excited now here's franois
[00:08:02] cholet so he is the person behind the
[00:08:04] arc AGI prize one of the original sort
[00:08:07] of thought leaders in the space that
[00:08:08] came up with this whole idea he is ex
[00:08:11] Google and his idea was simple like
[00:08:13] there's a lot of stuff that these large
[00:08:15] language models these neural Nets these
[00:08:17] AIS can do but is it truly intelligence
[00:08:20] is it intelligence like human
[00:08:22] intelligence is it General right so a
[00:08:24] lot of these models can beat humans at
[00:08:27] let's say chess or the game of Go but is
[00:08:29] it memorization High computational
[00:08:31] ability or is it sort of this general
[00:08:33] intelligence just like humans possess
[00:08:35] and so the whole point of this Arc AGI
[00:08:37] Benchmark was to come up with a lot of
[00:08:40] these questions that would be easy for
[00:08:43] humans but would be nearly impossible
[00:08:45] for something that simply memorized and
[00:08:48] spit out information and there's a whole
[00:08:51] lot that goes into that making sure that
[00:08:53] that's not happening and we've covered
[00:08:54] before but the point is this RI
[00:08:58] Benchmark was specifically made to crush
[00:09:00] neural Nets and it did so very
[00:09:03] effectively very few models were able to
[00:09:05] score as even close to that of a human
[00:09:08] so here's his post uh kind of in
[00:09:10] response to open ey's announcement of
[00:09:13] the 03 model now I'm sure he knew the
[00:09:15] results before we did but he posted this
[00:09:17] after the announcement saying today open
[00:09:19] announced 03 its next gen reasoning
[00:09:22] model we've worked with open AI to test
[00:09:23] it on the Ari and we believe it
[00:09:26] represents a significant breakthrough in
[00:09:28] getting AI to adapt to novel tasks it
[00:09:32] scores 75.7 on the semi-private eval in
[00:09:35] low compute mode so that's where the
[00:09:37] they meet the $10,000 limit and 87.5 in
[00:09:41] high compute mode where it spends
[00:09:42] thousands of dollars per task right
[00:09:44] again we think it's 300 plus th000 for
[00:09:46] the whole test and this line I think is
[00:09:50] kind of crucial here cuz remember this
[00:09:52] is a person that knows a thing or two
[00:09:54] when it comes to intelligence he wrote
[00:09:56] the book on it or at least a number of
[00:09:59] paper for analyzing exactly what
[00:10:01] intelligence is how to measure it and
[00:10:03] what does it mean to have intelligence
[00:10:04] in machines here's an essay he wrote in
[00:10:07] 2017 the limitations of deep learning
[00:10:10] he's saying despite our progress on
[00:10:12] machine perception we are still very far
[00:10:14] from Human level AI our models can only
[00:10:17] perform local generalization adapting to
[00:10:20] new situations that may stay very close
[00:10:22] from past data while human cognition is
[00:10:25] capable of extreme generalization
[00:10:27] quickly adapting to radically novel
[00:10:29] situations or planning for long-term
[00:10:31] future situations so this wasn't a
[00:10:34] person that was like hooray AI is going
[00:10:35] to solve everything AI is super super
[00:10:37] smarts better than humans No in fact
[00:10:39] it's I don't want to say the opposite
[00:10:41] but he was reserved he was saying and
[00:10:43] again that was 2017 certainly long while
[00:10:45] ago but the whole point of this Arc AGI
[00:10:47] prize was sort of to stump these neural
[00:10:50] Nets by having them actually reason
[00:10:54] through something without relying on the
[00:10:56] data without relying on memorization in
[00:10:59] other words could it solve novel tasks
[00:11:01] tasks it hasn't seen before and also
[00:11:04] tasks that aren't just a Brute Force
[00:11:06] approach where it just you know like
[00:11:07] chests it runs it can run through a
[00:11:09] million different sequences of moves and
[00:11:11] see which ones turn out better which
[00:11:14] again we have that we have super
[00:11:15] intelligence for chess we have super
[00:11:17] intelligence for go but we don't have we
[00:11:20] don't have super intelligence that's
[00:11:21] General up until now we in question if
[00:11:23] we've had any artificial intelligence
[00:11:25] that's General that's equal to humans
[00:11:28] and so here what he's saying is yes it's
[00:11:30] very expensive right that
[00:11:33] 87.5 you know hundreds of thousands of
[00:11:35] dollars likely again at the retail cost
[00:11:38] right I'm sure open AI might be getting
[00:11:39] that cheaper but still very expensive
[00:11:41] but it's not just brute it's not a Brute
[00:11:44] Force he's saying these capabilities are
[00:11:48] new territory that's very important to
[00:11:50] understand this is New Territory and
[00:11:53] they demand serious scientific attention
[00:11:56] so notice the man himself right who who
[00:11:58] who was the thought leader behind RI
[00:12:00] saying this is New Territory the
[00:12:02] president of RI is saying we all need to
[00:12:05] sort of find new intuitions for how AI
[00:12:09] Works what it can do these are not
[00:12:11] people that have always thought this
[00:12:13] these are very smart very knowledgeable
[00:12:15] people that are adjusting their world
[00:12:18] view right they're looking at these two
[00:12:20] yellow dots and they're saying huh this
[00:12:23] is New Territory and here he continues
[00:12:26] so is this AGI he says while the new
[00:12:30] model is very impressive and represents
[00:12:31] a big milestone on the way towards AGI I
[00:12:34] don't believe this is Agi there's still
[00:12:37] a fair number of very easy Arc agi1
[00:12:40] tasks that 03 can't solve and we have
[00:12:43] early indications that Arc AGI 2 will
[00:12:46] remain extremely challenging for 03 this
[00:12:49] shows that it's still feasible to create
[00:12:51] unsaturated interesting benchmarks that
[00:12:53] are easy for humans yet impossible for
[00:12:56] AI without involving specialist
[00:12:58] knowledge we will have AGI when creating
[00:13:00] such evals becomes outright impossible
[00:13:03] so this is Jason a researcher at open AI
[00:13:06] he's saying 03 is very performant more
[00:13:08] importantly progress from 01 to03 was
[00:13:10] only 3 months which shows how fast
[00:13:12] progress will be in the new paradigm of
[00:13:15] reinforcement learning on Chain of
[00:13:17] Thought to scale inference compute way
[00:13:19] faster than pre-training Paradigm of new
[00:13:21] model every 1 to two years again there's
[00:13:23] this idea that well we've hit a wall
[00:13:25] with AI progress that we can't keep uh
[00:13:28] growing the computer comp for the
[00:13:29] pre-training right we can just keep
[00:13:31] getting the models bigger therefore
[00:13:34] everything's going to slow down AI
[00:13:36] progress has stalled it's slowing down
[00:13:39] several news outlets reported as if it
[00:13:41] was in fact the case this is showing
[00:13:43] that it's maybe the opposite instead of
[00:13:46] it slowing down we've kicked it into
[00:13:48] high gear because now we're scaling as
[00:13:50] he says in this new paradigm right this
[00:13:52] new approach where we're using Chain of
[00:13:54] Thought to scale inference compute
[00:13:56] meaning that so that idea that these
[00:13:58] models have their sort of internal
[00:13:59] monologue that they're allowed to think
[00:14:01] through stuff before answering and we're
[00:14:03] able to sort of increase how much
[00:14:05] resources we want to spend on that with
[00:14:07] more resources they're getting a lot
[00:14:09] better and here's noome Brown
[00:14:11] researching reasoning at openi he says
[00:14:15] we have every reason to believe this
[00:14:18] trajectory will continue meaning that to
[00:14:21] all the people that have convinced
[00:14:23] themselves that this train is stopping
[00:14:25] any day now we're about to hit that wall
[00:14:28] again I wouldn't bet on it so December
[00:14:31] 20th 2024 we've hit some Milestone I'm
[00:14:36] sure there'll be people that will say
[00:14:38] this is not AGI and certainly we don't
[00:14:40] all have one sort of definition of what
[00:14:43] AGI means as s Al said recently it's
[00:14:46] probably not just some threshold that we
[00:14:47] pass it's probably more of a gradual
[00:14:49] process but it's also just a milestone
[00:14:52] along the way one of the cases it seems
[00:14:54] like we've passed some Milestone here
[00:14:57] whether you're willing to call it AGI or
[00:14:58] not not to me personally I feel like
[00:15:01] calling it feel like calling today being
[00:15:03] you know AGI day early today I was at
[00:15:05] lunch with some people that were
[00:15:07] considering doing a startup in the
[00:15:09] biotech medical device space and they
[00:15:12] were throwing some ideas around they
[00:15:13] were kind of discussing it I pulled out
[00:15:15] my phone which had you know which had
[00:15:18] Chad PT on it and I gave him some of the
[00:15:20] constraints and so like the team of
[00:15:21] people that were talking about it they
[00:15:22] had sort of three key people in that
[00:15:24] potential startup that they're thinking
[00:15:25] about each with their own kind of set of
[00:15:27] skills one is very familiar with the FDA
[00:15:30] approval process one is really just kind
[00:15:32] of a top tier engineer so they they all
[00:15:33] kind of have their own little things
[00:15:35] that they're doing so I typed into Chad
[00:15:37] GPT kind of like what we're talking
[00:15:39] about and kind of briefly describe s of
[00:15:41] their abilities I'm like based on this
[00:15:42] give you an idea for a potential product
[00:15:45] the answer chbt gave I think flored them
[00:15:49] because it was really good it's
[00:15:52] something that we kind of struggled to
[00:15:54] come up with it made a lot of sense now
[00:15:57] that might have been luck maybe if we
[00:15:58] asked it or three different ideas maybe
[00:16:00] the other two would be horrible but you
[00:16:02] know earlier in this video I uploaded
[00:16:04] this little screenshot asked it to
[00:16:05] figure out what the retail cost might be
[00:16:07] and you know what it it knew what I was
[00:16:09] talking about it's able to look at that
[00:16:11] chart figure out what the heck it is
[00:16:14] that I'm trying to say then figure out
[00:16:16] the math and give me the answer I mean
[00:16:17] think about approaching random people on
[00:16:19] the street and telling them hey you see
[00:16:21] this retail cost here well that retail
[00:16:23] cost is is for tokens like you spend
[00:16:25] tokens this how much it cost so what
[00:16:26] goes here how many people would be able
[00:16:29] to tell you the answer just based on
[00:16:31] that minimal amount of information I
[00:16:33] mean certainly some percentage of them
[00:16:34] it's not 100% but it's getting to the
[00:16:36] point where it's just sort of like
[00:16:37] quicker on the uptake than a lot of
[00:16:39] people it's I don't want to say smarter
[00:16:41] but it's just better at stuff like this
[00:16:42] than a large portion of the population
[00:16:45] this wouldn't be a trivial problem for
[00:16:47] everybody and this is the old news model
[00:16:50] from 3 months ago also did you catch
[00:16:52] that the 03 mini is going to be much
[00:16:55] better that the 01 at at coding but also
[00:16:58] with a massive cost reduction sem alment
[00:17:01] continues I expect this trend to
[00:17:03] continue but also that the ability to
[00:17:05] get marginally more performance for
[00:17:08] exponentially more money will be really
[00:17:11] strange so anyways I think I'll leave it
[00:17:13] there let me know what you think are you
[00:17:16] comfortable calling today AGI day if not
[00:17:19] what's missing what would it take to
[00:17:21] convince you that we have something like
[00:17:24] AGI do you have some specific metrics
[00:17:26] some specific benchmark that needs to
[00:17:28] hit before you're willing to call it
[00:17:30] that more to come soon if you made this
[00:17:32] part thank you so much for watching my
[00:17:33] name is Wes rth and I'll see you next
[00:17:35] time
